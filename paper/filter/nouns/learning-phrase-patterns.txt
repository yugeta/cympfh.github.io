#
Learning
Phrase
Patterns
for
Text
Classification
##
Intro
テキスト
分類
N
-
gram
十分
精度
ドメイン
特
化
こと
application
依存
こと
一般
性
n
-
gram
補充
素性
一つ
phrase
pattern
##
先行
###
Jaillet
+,
2006
topic
categorization
###
Wiebe
+,
2005
文章
一人称
教師
ナシ
これ
目的
語
フレーズ
パターン
分類
先行
研究
精度
###
Sun
+,
2007
二
外国
語
学習
者
文法
検出
###
Thur
+,
2010
and
Davidov
+,
2010
Twitter
Amazon
レビュー
皮肉
文
検出
###
Zhang
+,
2010
memo
/
N
10
-
1108
.
md
紹介
とおり
N
-
gram
精度
#
手法
##
phrase
pattern
普通
パターン
場合
素
やつ
拡張
バージョン
パターン
定義
パターン
文
マッチ
定義
###
素
phrase
pattern
文
word
列
`[
u
1
,
u
2
..
u
[
n
]]`
の
同様
phrase
pattern
word
列
`[
w
1
,
w
2
..
w
[
m
]]`
これ
先
文
マッチ
sub
sequence
こと
i
.
e
.
```
haskell
sentence
=
[
u
1
,
u
2
..
u
[
n
]]
pattern
=
[
w
1
,
w
2
..
w
[
m
]]
n
>=
m
exist
j
=
[
j
1
,
j
2
..
j
[
m
]]
i
1
<
i
2
=>
j
[
i
1
]
<
j
[
i
2
]
forall
i
.
w
[
i
]
==
u
[
j
[
i
]]
```
###
extend
語
列
word
class
利用
word
class
POS
polarity
制限
word
`
w
`
class
(
文脈
依存
)
`{
c
1
..
cn
}`
とき
```
w
->
{
w
,
c
1
..
cn
}
```
拡張
文
phrase
pattern
とも
拡張
適用
マッチ
こと
定義
最後
`==`
`
subset
`
i
.
e
.
```
haskell
sentence
=
[
u
1
,
u
2
..
u
[
n
]]
pattern
=
[
w
1
,
w
2
..
w
[
m
]]
n
>=
m
exist
j
=
[
j
1
,
j
2
..
j
[
m
]]
i
1
<
i
2
=>
j
[
i
1
]
<
j
[
i
2
]
forall
i
.
w
[
i
]
`
subset
`
u
[
j
[
i
]]
```
##
learning
拡張
バージョン
phrase
pattern
学習
アルゴリズム
一つ
他
CloSpan
の
###
PrefixSpan
(
Pei
,
Han
+,
2001
)
コーパス
`
D
`
(
文
集合
)
閾値
`
f
`
以上
頻度
よう
素
phrase
pattern
.
python
-
like
コード
以下
これ
prefix
`
rho
`
先頭
再帰
的
よう
再帰
パターン
`
rho
=
[]`
スタート
```
python
def
PrefixSpan
(
D
,
rho
,
f
):
P
=
[]
#
pattern
set
as
return
value
A
=
[]
#
new
patterns
for
_
each
a
in
D
:
#
a
is
a
token
rho
'
=
append
(
rho
,
a
)
A
.
append
(
rho
')
if
match
_
freq
(
D
,
p
)
>=
f
for
_
each
a
in
D
:
#
a
is
a
token
rho
'
=
assemble
(
rho
,
a
)
A
.
append
(
rho
')
if
match
_
freq
(
D
,
p
)
>=
f
P
=
P
.
extend
(
A
)
for
_
each
rho
'
in
A
:
D
'
=
project
(
D
,
rho
')
B
=
PrefixSpan
(
D
',
rho
',
f
)
P
=
P
.
extend
(
B
)
return
P
```
`
match
_
freq
`
マッチ
回数
`
append
`
`
assemble
`
パターン
トー
クン
パターン
```
python
def
append
(
rho
,
a
):
return
rho
.
append
({
a
})
def
assemble
(
rho
,
a
):
init
=
rho
[
0
:-
1
]
last
=
rho
[-
1
]
return
init
.
append
(
last
.
union
({
a
}))
```
パターン
`[{
w
1
,
c
1
..
c
1
}
..
{
wn
,
cn
..
cn
}]`
`
s
`
方法
-
`[{
w
1
,
c
1
..
c
1
}
..
{
wn
,
cn
..
cn
},
{
s
}]`
#
append
-
`[{
w
1
,
c
1
..
c
1
}
..
{
wn
,
cn
..
cn
,
s
}]`
#
assemble
あと
コーパス
D
パターン
rho
project
マッチ
文
フィルタ
リング
もの
```
python
def
Project
(
D
,
rho
):
D
'
=
[]
for
_
each
s
in
D
:
D
'
=
D
'.
append
(
s
)
if
match
(
rho
,
s
)
return
D
'
```
論文
の
複雑
効率
よう
上
場合
パターン
`[
w
1
]`
採択
`
project
`
それ
マッチ
文
次
`[
w
1
,
w
2
]`
先頭
の
`
project
`
定義
マッチ
文
マッチ
文
マッチ
後ろ
部分
こと
`[
w
2
]`
##
尺度
先
アルゴリズム
頻度
尺度
パターン
採択
相互
情報
量
ほう
コーパス
D
クラス
`
Y
=
1
,
2
..
K
`
変数
`
X
`
パターン
マッチ
(`
X
=
0
,
1
`)
定義
通り
```
haskell
I
X
Y
=
sum
[
sum
[
(
p
x
y
)
*
log
((
p
x
y
)
/
(
p
x
)
/
(
p
y
))
|
y
<-
[
1
..
K
]
]
|
x
<-
[
0
,
1
]
]
```
次
よう
計算
(
計算
効率
)
```
haskell
p
_
given
x
y
--
probability
of
x
given
y
I
X
Y
=
sum
[
sum
[
(
p
_
given
x
y
)
*
(
p
y
)
*
log
((
p
_
given
x
y
)
/
p
_
x
)
|
y
<-
[
1
..
K
]
]
|
x
<-
[
0
,
1
]
]
where
p
_
x
=
sum
[
p
_
given
x
y
'
*
p
y
'
|
y
'
<-
[
1
..
K
]
]
```
パターン
`
p
`
`
X
`
パターン
拡張
時
それ
`
XE
`
```
p
(
XE
=
1
|
y
)
<=
p
(
X
=
1
|
y
)
```
相互
情報
量
上限
```
sup
_
E
I
(
XE
;
Y
)
```
存在
(
まじ
？？？)
改訂
版
アルゴリズム
`
ExtendedPrefixSpan
`
```
python
def
ExtendedPrefixSpan
(
D
,
rho
,
Theta
):
P
=
[]
for
_
each
t
in
D
:
rho
'
=
rho
.
append
(
t
)
rho
'
相互
情報
量
閾値
以上
P
=
P
.
append
(
rho
')
else
上限
閾値
D
'
=
project
(
D
,
rho
')
P
'
=
ExtendedPrefixSpan
(
D
',
rho
',
Theta
)
P
=
P
.
extend
(
P
')
return
P
```
#
Word
Classes
##
Lemma
canonical
form
of
a
word
こと
```
haskell
{
go
,
goes
,
going
,
went
gone
}
->
go
```
NLTK
WordNet
lemmatizer
##
Word
shape
大文字
方
全部
大文字
最初
ドット
連結
大文字
省略
形
##
POS
Stanford
log
-
lenear
POS
tagger
の
英語
中国
語
##
Named
entity
(
NE
)
テキスト
分類
これ
大事
素性
```
(
sentence
,
word
)
->
class
({
Location
,
Person
,
Organization
,
Time
,
Date
})
```
Stanford
conditional
random
field
-
based
NE
recognizer
(
NER
)
もの
##
LIWC
dictionary
($
89
.
95
)
Linguistic
Inquiry
and
Word
Count
(
LIWC
)
単語
64
(
感情
?)
クラス
分類
Facebook
奴
文脈
依存
一つ
単語
分析
[
LIWC
:
Linguistic
Inquiry
and
Word
Count
](
http
://
www
.
liwc
.
net
/
tryonline
.
php
)
##
MPQA
subjectivity
lexicon
under
GNU
GPL
自己
申告
個人
情報
即座
ダウンロード
[
Subjectivity
Lexicon
|
MPQA
](
http
://
mpqa
.
cs
.
pitt
.
edu
/
lexicons
/
subj
_
lexicon
/)
```
(
word
,
POS
)
->
class
```
8222
(
word
,
POS
)
登録
```
type
=
weaksubj
len
=
1
word
1
=
dominate
pos
1
=
verb
stemmed
1
=
y
priorpolarity
=
negative
```
##
manual
>
we
use
various
word
listsc
onstructed
by
linguists
who
have
looked
at
data
related
to
some
of
our
tasks
.
手作業
クラス
単語
リスト
これ
タスク
ごと
トピック
人間
後
実験
例
```
haskell
AGREEMENT
=
[
right
,
agree
,
true
]
DISAGREEMENT
=
[
doubt
,
inappropriate
]
ALIGNMENT
=
AGREEMENT
++
DISAGREEMENT
MODAL
=
[
could
,
should
]
NEGATIVE
_
DISCOURSE
_
ORDER
=
[
however
,
but
,
nevertheless
]
```
##
automatic
1
次
マルコフ
モデル
word
クラスタリング
クラス
数
10
,
100
,
1000
Brown
+,
1992
"
Class
-
based
n
-
gram
models
of
natural
language
"
#
実験
n
-
gram
他
素性
十分
分類
可能
タスク
しょうが
それなり
タスク
３つ
-
speaker
role
-
alignment
move
-
authority
claim
初め
訓練
データ
パターン
学習
n
-
gram
場合
パターン
場合
比較
公平
ため
n
-
gram
3
-
gram
パターン
さ
3
-
Maximum
entropy
classification
+
`
P
(
c
|
d
)
=
1
/(
Z
d
)
*
exp
(
sum
_
i
[
lambda
_
i
*
f
_
i
])`
-
5
-
fold
cross
validation
##
Speaker
role
ニュース
ショー
(
人
,
人
言葉
)
人
ショー
役割
役割
Host
,
Guest
,
Voice
bite
Liu
+
80
%
48
English
talks
and
90
Mandarin
talks
録音
REF
(
Reference
human
transcripts
)
ASR
(
automatic
speech
recognition
)
output
(
using
SRI
Decipher
ASR
system
)
対象
ASR
こと
註意
英語
22
.
8
%
北京
語
38
.
6
%
単語
/
文字
kappa
=
0
.
67
/
0
.
78
##
Alignment
move
ネット
上
議論
参加
者
同意
(
positive
)、
異論
(
negative
)
文
pos
/
neg
アノテータ
pos
アノテータ
neg
pos
+
neg
ラベル
実験
の
Wikipedia
talk
page
211
English
pages
and
225
Chinese
pages
kappa
=
0
.
50
/
0
.
53
pos
/
neg
両方
よう
面倒
文
pos
/
none
,
neg
/
none
２つ
分類
器
##
Authority
claim
>
showing
her
knowledge
or
experience
with
respect
to
a
topic
,
or
using
some
external
evidence
to
support
herself
Marin
+,
2010
:
Unigram
(
外
ページヘ
引用
)
339
English
pages
and
225
Chinese
pages
発言
ごと
authority
claim
kappa
=
0
.
59
/
0
.
73
全体
20
%
authority
claim
##
Result
表
適宜
参照
こと
ここ
こと
Table
I
PrefixSpan
ExtendedPrefixSpan
差
-
0
.
2
%
+
4
.
1
%
Table
II
VII
baseline
(
with
only
n
-
gram
)
pattern
(
with
each
class
)
比較
Speech
role
REF
ASR
十分
結果
頑強
manual
利用
それ
最強
Wikipedia
English
pages
alignment
パターン
```
i
ALIGNMENT
MODAL
a
POSITIVE
#
idea
```
英語
パターン
場合
２つ
トーク
ン
連続
出現
マッチ
わけ
上
よう
`#`
の
連続
こと
意味
初め
