# 再近傍探索

## title
Near-Optimal Hashing Algorithms
for Approximate Nearest Neighbor
in High Dimensions  

内容:
LSH (Locality Sensitive Hashing) を用いた、最近傍探索の解法

:url http://people.csail.mit.edu/indyk/p117-andoni.pdf

## 最近傍探索に対する一つの解法、kd木

空間を(2)分割してって木構造にするやつ。
空間軸に垂直なので分割してる。
空間上に与えられた点の数だけ、空間を分割する。
分枝限定法っていう枝刈ができる。
`log(N)` でできるんだって。すごいね。

- Cons: 空間の次元が大きいとやばい。

- Idea: ハッシュは次元を自由に潰せる。

## LSHの提案

ハッシュ関数の衝突する確率を利用する。

何か期待する距離 `||` に対して、

- `|x - y| < R` => 高い確率で、x,yのハッシュは衝突
- `|x - y| > c * R` => 低い確率で、衝突

という性質を locality sensitive と呼ぶ。
そしてこの性質を持つ hash を LSH という。

複数のハッシュから選んで並べて出力すれば、
「合体ハッシュ関数」は容易に作れる。
複数使うことで衝突の確率をの差を顕著にすることも、
また容易である。

合体ハッシュ関数を`L`個、用意して、どれか一つでも衝突すれば、
近傍であると考える。

```haskell
L = n ^ rho
  where
    rho = log P / log Q
```

とすると、失敗確率が近似で、計算量もsublinearになってよい。

## LSH の例。

### データがバイナリ列のとき、正射影 (d次元から1次元を見る)

d次元中、ハミング距離 `h` の二つが衝突する確率は
`(d - h) / d`

### L1 距離

ランダムに直線を選択し、その直線を区間に分割する。
クエリとなる点をその直線に下ろした垂線の足がどの区間にあるかをハッシュとする。

### min-hash

一つのクエリであるところの点が集合のとき。

集合の類似度として Jaccard係数がある

```haskell
sim u v = (size u and v) / (size u or v)
```

MinHashのアイディアは非常に単純です．
はじめに，適当なハッシュ関数 `h`を用意します．
（ハッシュ関数の値域は十分に大きく，衝突しないとします）．
次に `v = {a1 .. aN}` 中の各値をハッシュ関数を利用し，
ハッシュ値
`{h a1 .. h aN}`
を求めます。
最後に，これらのハッシュ値の最小値
`min {h a1 .. h aN}`
を記録します。

さて，ランダムにハッシュ関数をとってきた時，二つの集合v, wのハッシュ関数による最小値が一致する確率 はどのようになるでしょうか．これが実はJaccard係数に一致します．

```haskell
sim v w = Pr min {h a for a <- v} = min {h b for b <- w}
```

### 超平面

原点を通る超平面をランダムに選ぶ。
クエリとなる点がその平面からどちら側にあるか。

### ユークリッド距離

空間を適当な区間に分割して、どれにあるか。
グリッドよりは、例えば超球に分割するのが、計算上も都合がよい。


# コサイン類似度の話

n名詞がそれぞれk次元ベクトルで表現されてるとき、
2名詞の類似度の計算はコサイン類似度を使えば
O(k)
かかって、
n名詞全ての2つの類似度の計算は
O(n<sup>2</sup>k)
かかる。

乱択を使ってそれを
`O(nk)`
にする話。


## LSH関数

2名詞 `r`, `u` についてのハッシュ関数 `h` を次のように定める。

```haskell
h u v = if inner-dot u v >= 0 then 1 else 0
```

衝突する確率 `Pr-coll` は、その偏角の絶対値が 90度 以下だか未満だかになる確率だから

```haskell
Pr-coll u v = 1 - (arg u v) / pi
```

逆に、この確率を使って、コサイン類似度が次のように表現できる

```haskell
cos (arg u v) = cos (pi * (1 - Pr-coll)) -- (*)
```

## アルゴリズム

n単語の集合を`N` とする。

- `u <- N`
- `r = [n | n <- N, random]; length r == d`

```haskell
bits u = map (h u) r
```

これを、`u` を表現するビット列だとする。
n単語すべてについてこれをやる。
近い物を見ればいい。
近いもの、は、ビット列だからハミング距離を見るのがいい。

ハミング距離が `c` となる確率は、
(d-c) 回衝突して、c 回衝突する確率である。

ここで、ハミング距離が近いことが、
コサイン類似度も高くなることを意味する、と、
`(*)` によって示せる。

## ハミング距離の計算

ハミング距離を見るだけでも O(n<sup>2</sup>d) かかるんだけど、
なんか乱択する。
ほんとかよ。

