###################
## 2013-12-11.mkd
# ML-Ask のソースコードを読んだメモ

# アノテートタグ
CAO は次のような感情をアノテートする
(全部データベースを持っている)

- emotems
    + INT 挨拶，感動詞
    + EXC [三点リーダ！？〜♪]を含むか
    + VUL 下品な言葉
    + END 「ちゃん」
    + GIT 擬態語
    + EMO 顔文字

emo_val とは 含む emotems の数
重複する
例えば「!!」は2つと数えられる

- emotions
    + AWA 哀れむ
    + HAJ 恥ずかしがる
    + IKA 怒り
    + IYA 嫌
    + KOW 怖がる
    + ODO 驚き
    + SUK 好き
    + TAK 昂ぶり
    + YAS 安堵
    + YOR 喜び

次は二次元上のマッピング

    POS <-> NEG
    ACT <-> PAS (active or passive)

# アルゴリズムのチラ見

POS,NEGは出現した感情の数を数えてる

    YAS | YOR | SUK -> POS
    TAK | ODO | HAJ -> NEG

POSとNEGが同じ個数だったら POS_or_NEG とする
で，多い方を採用するけど
少ないほうがゼロでないなら頭に"mostly"を附ける

ACT,PASも同様

    TAK | ODO | HAJ | IKA | KOW -> ACT
    YAS | AWA -> POS
    IYA | YOR | SUK -> 無視

ACTとPOSが同じなら ACT_or_PAS をアノテート
mostlyは同様に附ける

というわけで
AWA, HAJ, IKA, IYA, KOW, ODO, SUK, TAK, YAS, YOR
これだけを信用すればいいのではないかな

# CVS

    あまり***ない
    全く***訳じゃない

こういうパターンを
    ***
の前と後それぞれ用意してる
そのパターンの時の処理はperlなんて読めないけど
「あまり」でも「全く」でも同じような処理しかしてない
これ公開してるのはわざと手を抜いたバージョンなんじゃないか

# CAO, ML-Ask のまとめ {{{1

公開されてるのはCAOは顔文字の識別
ML-Askは文から感情分析．ML-Askの中でも顔文字の識別をしてEMOタグをつけてくれてるけどやっぱり感情分析はしてないじゃん
スライドの言ってること嘘なんじゃないの？？？？

http://arakilab.media.eng.hokudai.ac.jp/~ptaszynski/repository/cao.htm
で公開されてる
http://arakilab.media.eng.hokudai.ac.jp/~ptaszynski/repository/files/emoticon-raw-stats.zip
これは顔文字の 目-くち-目 のパターンを感情ごとにいくつ出てきたかの数字
付きでまとめられてる
しょーがないからこれ使ったのが 
https://github.com/cympfh/working/blob/master/index.js
だけど

どうなんだろう？
顔文字のパターンが少ないのはもう諦める

# ダメと思うところ

CVSが実装なされてるにせよ
基本的には特徴的なワードがデータベースに合致したら
「怒りパラメータをインクリメント」
みたいなことをやっているだけ
さて何を学べるか
一文の中で感情の変化が起こることを想定していない

## ここで我らが yukari_tamura さんのツイットを

https://twitter.com/yukari_tamura/status/409329917818454016
https://twitter.com/yukari_tamura/status/403084224145522690
https://twitter.com/yukari_tamura/status/401886795299700736

すごい．さすが田村ゆかりさん．いくらでも欲しいソースをくれる
ほんとすごい

つまり一種の物語を140文字の中で，自分を主人公にして演じてくれてる
CAOはなんか2ちゃんとかアサヒニュースをコーパスにしてたけど
Twitterを対象にする私はyukari_tamuraさんを対象にする私はもっと
違うことをやらねばねばねば


# さてさて

20万のツイットについてML-Askなるものを試そうとしたけど20万は時間かかりすぎ
ていうかこれ遅いんだよな

一つのツイット一回にぶち込むと前に書いたように全体に対して感情のバッグを出力するだけだから
文ごとに区切って文ごとにぶち込んだ
4853だけ試せた

## そも文とは

簡単に

    var re = /^(.*?)([ｗ。！\!\?？…])+(.*)$/;

## 例

念の為，文に区切る前と区切った後両方見る

    林檎のミルフィーユ飲む。ラムレーズンアイスー！！！ はよ飲んでニコ生向かわねば｡ﾟ(ﾟ´Д｀ﾟ)ﾟ｡
    |emotive|emo_val=5|INT:んで よ |EXC:！ ！ ！ |EMO:(ﾟ´Д｀ﾟ)||emotions:(0)

    林檎のミルフィーユ飲む。|non-emotive
    ラムレーズンアイスー！！！|emotive|emo_val=3|EXC:！ ！ ！||emotions:(0)
    はよ飲んでニコ生向かわねば｡ﾟ(ﾟ´Д｀ﾟ)ﾟ｡|emotive|emo_val=3|INT:んで よ |EMO:(ﾟ´Д｀ﾟ)||emotions:(0)

    ちょっとタグｗｗｗでもわかる……雅様ぁ(｀;ω;´)薄桜鬼の時もかなり複雑だったし。嬉しいけど…雅様ぁぁああ　
    |emotive|emo_val=5|INT:ちょっと ああ |EXC:… … … |EMO:(´))||emotions:(1)|YOR:嬉しい||2D|POS|ACT_or_PAS

    ちょっとタグｗ|emotive|emo_val=1|INT:ちょっと||emotions:(0)
    でもわかる…|emotive|emo_val=1|EXC:…||emotions:(0)
    雅様ぁ(｀;ω;´)薄桜鬼の時もかなり複雑だったし。|non-emotive
    嬉しいけど…|emotive|emo_val=1|EXC:…||emotions:(1)|YOR:嬉しい||2D|POS|ACT_or_PAS
    雅様ぁぁああ　|emotive|emo_val=1|INT:ああ||emotions:(0)

うーん，こ
顔文字を分析してくれなかったらゴミだわ

俺々顔文字分析使っちゃうと

    (ﾟ´Д｀ﾟ)
    { anger: 0,
      dislike: 0,
      excitement: 0,
      fear: 0,
      fondness: 0,
      joy: 0,
      relief: 0,
      shame: 0,
      sorrow: 1,
      surprize: 0 }

みたいになる予定
いや，上の数字は嘘で，こんな顔文字がデータベースになかったから自分で追加しちゃったから

やるとしたら顔文字データベース自分で作り直したいわな
どうせこれも人手で作ったようなデータベースだし
でもひとつの感情について100から1000もあるみたい
大変だろうな，それは
やっぱ人手じゃだめかな

分かりやすい感情的なテキストをラベルにして顔文字を学習するのがいいかもしれない


    あ〜ちゃん、23歳のお誕生日おめでとう(*´◒`*)♡ いつもニコニコ笑顔で、みんなから愛されてて、頑張り屋さんで、泣き虫なあ〜ちゃんが大好きです。|emotive|emo_val=5|INT:んで あ おめでとう なあ |EXC:〜 〜 |END:ちゃん ちゃん||emotions:(3)|SUK:大好き 好き|AWA:泣き|YOR:笑顔||2D|mostly_POS|mostly_PAS

    誕生日おめでとう＼(^o^)／涙もろくて面白くてファンを 大切にしてくれるあ～ちゃんが大好きだぁぁぁ I！|emotive|emo_val=4|INT:おめでとう あ |EXC:！ |END:ちゃん||emotions:(4)|TAK:涙|SUK:大好き 好き|AWA:涙|YOR:面白い||2D|mostly_POS|ACT_or_PAS

ホントに疑いたくなるレベルなんだけど

###################
## 2013-12-19.mkd
# ML-Ask での感情の遷移

tweetはtw/twsが元でurl, hashtag, @hoge を取り除いてから節ごとに取り除く

$ wc tw/tws
   74589  219153 8288951 tw/tws

顔文字は直前の文に作用するとして，文の感情がなんだろうが顔文字を優先させる
文の頭の顔文字は直後に作用するとすればいいかもだけど
面倒だからまあいいや

1tweetで見つかった感情は重複を許して, 1 - 7 emotions であった

n-emotions
working/images/canvas${n}.png

5,6,7あたりは圧倒的に数が少ないから信用できないかも
バイグラムで再現できるか？
長さ2以上の物について，前後二つをカウントしてから総数で割った

# length = 2
|     | aware  | haji   | ikari  | iya    | kowa   | odoro  | suki   | takab  | yasu   | yorok |
|:----|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:------|
| awa | 0.009  | 0.001  | 0.001  | 0.014  | 0.002  | 0.002  | 0.01   | 0.007  | 0.003  | 0.012 |
| haj | 0      | 0.003  | 0.001  | 0.003  | 0.001  | 0.001  | 0.006  | 0.001  | 0.001  | 0.006 |
| ika | 0.002  | 0      | 0.004  | 0.007  | 0.002  | 0.001  | 0.006  | 0.003  | 0.001  | 0.005 |
| iya | 0.009  | 0.003  | 0.003  | 0.042  | 0.003  | 0.003  | 0.025  | 0.007  | 0.008  | 0.02  |
| kow | 0.002  | 0      | 0.001  | 0.007  | 0.007  | 0.001  | 0.004  | 0.002  | 0.002  | 0.005 |
| odo | 0.001  | 0      | 0      | 0.003  | 0.002  | 0.005  | 0.009  | 0.004  | 0.006  | 0.009 |
| suk | 0.01   | 0.003  | 0.004  | 0.026  | 0.011  | 0.006  | 0.134  | 0.021  | 0.016  | 0.049 |
| tak | 0.011  | 0.003  | 0.004  | 0.016  | 0.004  | 0.005  | 0.063  | 0.028  | 0.021  | 0.06  |
| yas | 0.001  | 0      | 0      | 0.004  | 0.001  | 0.001  | 0.006  | 0.003  | 0.003  | 0.005 |
| yor | 0.007  | 0.003  | 0.006  | 0.019  | 0.005  | 0.005  | 0.039  | 0.016  | 0.017  | 0.056 |

# length = 3
|     | aware  | haji   | ikari  | iya    | kowa   | odoro  | suki   | takab  | yasu   | yorok |
|:----|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:------|
| awa | 0.031  | 0.001  | 0.001  | 0.007  | 0.001  | 0.003  | 0.011  | 0.006  | 0.001  | 0.012 |
| haj | 0      | 0.002  | 0      | 0.003  | 0      | 0.002  | 0.007  | 0.001  | 0      | 0.002 |
| ika | 0.004  | 0      | 0.002  | 0.003  | 0      | 0      | 0      | 0.001  | 0      | 0.002 |
| iya | 0.011  | 0      | 0.003  | 0.043  | 0.003  | 0.001  | 0.022  | 0.007  | 0.006  | 0.018 |
| kow | 0      | 0      | 0.001  | 0.006  | 0.004  | 0      | 0.01   | 0.003  | 0      | 0.009 |
| odo | 0.002  | 0      | 0      | 0.004  | 0      | 0.004  | 0.006  | 0.001  | 0.002  | 0.012 |
| suk | 0.015  | 0.003  | 0.003  | 0.023  | 0.01   | 0.006  | 0.227  | 0.007  | 0.012  | 0.062 |
| tak | 0.011  | 0      | 0.002  | 0.01   | 0.009  | 0.004  | 0.029  | 0.01   | 0.003  | 0.031 |
| yas | 0      | 0      | 0      | 0      | 0      | 0.002  | 0.006  | 0.004  | 0.006  | 0.005 |
| yor | 0.01   | 0.007  | 0.006  | 0.02   | 0.008  | 0.006  | 0.052  | 0.008  | 0.01   | 0.09  |

# length = 4
|     | aware  | haji   | ikari  | iya    | kowa   | odoro  | suki   | takab  | yasu   | yorok |
|:----|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:------|
| awa | 0.011  | 0      | 0      | 0.011  | 0.006  | 0.004  | 0      | 0      | 0      | 0.015 |
| haj | 0      | 0      | 0.003  | 0      | 0      | 0      | 0.003  | 0      | 0      | 0     |
| ika | 0.011  | 0      | 0      | 0.006  | 0      | 0      | 0      | 0      | 0      | 0.006 |
| iya | 0.017  | 0      | 0      | 0.037  | 0      | 0.006  | 0.068  | 0.005  | 0.003  | 0.006 |
| kow | 0.006  | 0      | 0      | 0.011  | 0      | 0      | 0.022  | 0      | 0      | 0.011 |
| odo | 0      | 0      | 0      | 0.017  | 0      | 0      | 0      | 0      | 0      | 0.005 |
| suk | 0.002  | 0.003  | 0.011  | 0.03   | 0.022  | 0.011  | 0.395  | 0.002  | 0.005  | 0.029 |
| tak | 0.004  | 0      | 0      | 0      | 0.011  | 0      | 0.017  | 0.004  | 0      | 0.015 |
| yas | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0.002  | 0.002 |
| yor | 0.003  | 0      | 0      | 0.011  | 0      | 0.006  | 0.044  | 0.011  | 0.017  | 0.058 |

# length = 5
|     | aware  | haji   | ikari  | iya    | kowa   | odoro  | suki   | takab  | yasu   | yorok |
|:----|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:------|
| awa | 0      | 0      | 0      | 0      | 0.05   | 0      | 0.002  | 0      | 0      | 0.017 |
| haj | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| ika | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0.017 |
| iya | 0.05   | 0      | 0      | 0.044  | 0      | 0      | 0.055  | 0      | 0      | 0     |
| kow | 0.017  | 0      | 0      | 0.033  | 0      | 0      | 0      | 0      | 0      | 0     |
| odo | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0.004  | 0.012 |
| suk | 0.002  | 0      | 0      | 0.039  | 0      | 0      | 0.496  | 0.004  | 0      | 0.028 |
| tak | 0      | 0      | 0      | 0      | 0      | 0      | 0.021  | 0.004  | 0      | 0.017 |
| yas | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| yor | 0      | 0      | 0.011  | 0.017  | 0      | 0.017  | 0.006  | 0.017  | 0      | 0.024 |

# length = 6
|     | aware  | haji   | ikari  | iya    | kowa   | odoro  | suki   | takab  | yasu   | yorok |
|:----|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:------|
| awa | 0      | 0      | 0      | 0      | 0      | 0      | 0.055  | 0      | 0      | 0     |
| haj | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| ika | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| iya | 0.073  | 0      | 0      | 0.291  | 0      | 0      | 0.145  | 0.073  | 0      | 0     |
| kow | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| odo | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| suk | 0.055  | 0      | 0      | 0.145  | 0      | 0      | 0.055  | 0      | 0      | 0     |
| tak | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| yas | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| yor | 0      | 0      | 0      | 0      | 0      | 0      | 0.055  | 0      | 0      | 0.055 |

# length = 7
|     | aware  | haji   | ikari  | iya    | kowa   | odoro  | suki   | takab  | yasu   | yorok |
|:----|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:-------|:------|
| awa | 0      | 0      | 0      | 0      | 0      | 0      | 0.167  | 0      | 0      | 0     |
| haj | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| ika | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| iya | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| kow | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| odo | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| suk | 0.167  | 0      | 0      | 0      | 0      | 0      | 0.333  | 0      | 0      | 0     |
| tak | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| yas | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0      | 0     |
| yor | 0      | 0      | 0      | 0      | 0      | 0      | 0.167  | 0      | 0      | 0.167 |


目で見た感じ，似てなくはない

あぶすとらくとを書きました

###################
## 2014-01-07.mkd

## CeVIO の出力
* https://gist.github.com/cympfh/959658d4e437d02b09fe
* https://gist.github.com/cympfh/3516a68ecda2b1a85665

tweet列からこのxmlを出力させりゃあいい
これはすぐできる

## number of Text unit

dist [ 3, 181, 71, 34, 15, 16, 11, 7, 7, 5, 4, 3, 4, 1, , 1, , , , 1 ]
mean 2.607142857142857


###################
## 2014-01-08.mkd
# 手で作った正解データとML-Askとを比較してみてる

対応の表

    null -> null
    喜 笑 好 昂 安堵 -> 喜
    哀 嫌 怖 -> 哀
    恥 -> 恥
    怒 -> 怒
    驚 -> 驚

## まず全体の感情だけを比較してみた

364 tweets 中

* 232 tweets は完全に一致 (ML-Askが一つしかタグ付けしなかった)
    + その内 222 はどちらも null であった
    + 残り 10 tweets
* 18 tweets は ML-Ask による二つ以上のタグの中に正解タグがあった
* 残りは 114 tweets が不一致
    + 正解データでは null のもの 24
    + ML-Askｈでは null のもの 83
    + まるで違うもの 7 つ
        - 正解 : 恥 , ML-Ask : 哀+喜


## 手では null としたけどML-Askは何かタグ付けした例

    <tw awa> <span awa>クロノトリガーボロ泣きし</span><conj>ながら</conj><span>やってた思い出 が</span> </tw>
    <tw yor> <span yor>イメージとまんまの爽やか系のﾋﾞｭﾝﾋﾞｭﾝ系でした！</span><span>あと予想より背が大きかった</span> </tw>
    <tw iya> <span iya>ユノジェジュンユチョンジュンスチャンミンいや、</span><span>やっぱ꒰꒪꒫꒪⌯꒱ㅎㅎㅎ</span> </tw>
    <tw suk> <span>ち！！</span><span>ん！！</span><span>こ！！！！！！</span><span>やばいわねついに誕生日(…</span><span>ですよね？</span><span>)ね！！！！！</span><span>ﾌｵｫｯｯｯ！！！ ！！！！</span><span>沈子や普段わたしはこんなこと言わない</span><conj>ってか</conj><span> 蕁麻疹引き起こさせる能力を持っ</span><conj>て</conj><span>いる</span><conj>けども</conj><span>、、、！！！！！！</span><span suk>沈子好きだぞ！！！！！！</span> </tw>
    <tw iya> <span>そい</span><conj>や</conj><span>！！</span> </tw>
    <tw iya> <em>(＝д＝)</em><span iya>　恒常的な政府からの施しなど真っ平御免だ。</span><span>私はそんなのいらない。</span><span>他の人がどうであれ。</span> </tw>
    <tw yor> <span yor>【ネガティブ短歌】公園で笑顔はじける子供たち夢を追いかけでもみんな死ぬ</span> </tw>
    <tw suk> <span suk>→変態リアル→世話好きな変態</span> </tw>
    <tw iya> <conj>いや</conj><span>もうありがとう</span> </tw>
    <tw odo> <span odo>恋のナツミショック</span> </tw>
    <tw yas> <span yas>平成24年2月15日よるほー</span> </tw>
    <tw iya> <span iya>（）さん【迷い人】　貧乏家庭の勤労少年。</span><span>少ない給料で自分の食費を削っ</span><conj>て</conj><span>古本を買う読書家さん。</span><span>古本屋で偶然見つ けた魔道書のようなものを開い</span><conj>て</conj><span>みたらそこは図書館でした。</span><span>来る直前に喧嘩別れした親友のことが気がかり</span> </tw>
    <tw iya> <span iya>ライブでさらにその輝きをいや増すパフュの太陽、</span><span>あ～誕23rd！！</span> </tw>
    <tw suk> <span>「</span><span>彼女は来年も、</span><span suk>僕のことを好きでい</span><conj>て</conj><span>くれるだろうか。</span><span>今年はタイミングがなかった</span><conj>から</conj><span>な。」</span> </tw>

<tw odo> <span odo>恋のナツミショック</span> </tw>
とか、完全に釣られちゃってるパターンだよね
たぶん「オイルショック」を驚きとしてしまうよね

## 逆に ML-Ask は null としたけど正解データは次の通り

    <tw yor> <span yor>あ〜ちゃんおめでとうなんだよー</span><em yor>(●´⌓`●)♥</em><span yor>はぴばなんだよー</span><em yor>(♡´꒳｀♡)ノ</em> </tw>
    <tw yor> <span>トビースペシャル</span><em yor>ｷﾀ*･゜ﾟ･*:.｡..｡.:*･゜(ﾟ∀ﾟ)ﾟ･*:.｡. .｡.:*･゜ﾟ･*</em><span>!!!!</span><span>〜</span> </tw>
    <tw yor> <span yor>お誕生日おめでとう～！！！！！</span> </tw>
    <tw yor> <span yor>よるほ~っ♪</span> </tw>
    <tw yor> <span>あ～ちゃんこと西脇綾香さん、</span><span yor>23歳のお誕生日おめでとうございます！！</span><span>去年は様々なことで心を痛めたかもしれません</span><conj>が</conj><span>、</span><span>今年はツアーでその力を存分に発揮し</span><conj>て</conj><span>いますね。</span><span yor>23歳のあ～ちゃんをたくさんの場所で見たいです！</span><span yor>本当におめでとうございます！！</span> </tw>
    <tw yor> <em yor>☆★☆</em><span yor>よるほー☆★☆</span> </tw>
    <tw yor> <span>/14が終わるー。</span><span yor>信ちん32thおめでとう☆サランヘヨー♡</span> </tw>
    <tw yor> <span yor>あ〜ちゃんおめでと─────────っ!!!</span> </tw>
    <tw odo> <span odo>トビーが曲に合わせ</span><conj odo>て</conj><span odo>歌った!!</span> </tw>
    <tw yor> <span yor>あ～ちゃん、</span><span yor>お誕生日おめでとー！</span> </tw>
    <tw yor> <span yor>あ～ちゃん、</span><span yor>お誕生日おめでとう！</span> </tw>
    <tw yor> <span yor>誕生日お</span><em yor>(・∀・)め(・∀・)で(・∀・)と(・∀・)</em><span yor>う！</span><span yor>あ〜ちゃん!!</span> </tw>
    <tw yor> <span yor>㊗あ～ちゃんお誕生日おめでとうございます。</span> </tw>

「ーーーーーーーーっ!!!」とか明らかに喜び表現じゃん。それは怪しいか



###################
## 2014-01-12.mkd
# SVM を良くするための素性選び

* total
* main
* before span -1
* before span -2
* before span -3
* after span +1
* after span +2
* after span +3
* -1 span
* +1 span
* -1 icon
* +1 icon
* -1 conj
* +1 conj

此の時

|          |                                |
| :------- | :---------------------------   |
| Prec     | 91 / 268 = 0.33955223880597013 |
| Recall   | 91 / 204 = 0.44607843137254904 |
| F        | 0.385593220338983              |

多分これが過去最高.
社会は厳しい

---

ここからdomainを変更しよう.
すなわち, em を例えば2つ以上含む場合に限定してはどうか

一気に勝負らしくなった！

|        |                            |
|:-------|:---------------------------|
| Prec   | 5 / 7 = 0.7142857142857143 |
| Recall | 5 / 7 = 0.7142857142857143 |
| F      | 0.7142857142857143         |


ちなみに、em 1つ以上、だと、前と変わらない

---

さらに

    C : 0.99, rbfSigma : 0.6

で、あと感情のベクトルは出現したかどうかの01ベクトルで

|        |                            |
|:-------|:---------------------------|
| Prec   | 4 / 4 = 1                  |
| Recall | 4 / 7 = 0.5714285714285714 |
| F      | 0.7272727272727273         |

まあ、運だけどね

---

* C : 0.99, rbfSigma : 0.6
* total
* main
* before span 1
* before span 2
* before span 3
* after span 3
* +1 icon
* -1 icon
* +1 conj
* -1 conj

    Prec   | 5 / 5 = 1
    Recall | 5 / 7 = 0.7142857142857143
    F = 0.8333333333333334

母数が小さいから正解データ増やしましょう

* C : 0.99, rbfSigma : 0.6
* total
* main
* before span 1
* before span 2
* before span 3
* after span 3
* +1 icon
* -1 icon
* before conj
* after  conj

| Prec   | 117 / 133 = 0.8796992481203008 |
| Recall | 117 / 133 = 0.8796992481203008 |
| F      | 0.8796992481203008             |

一番すばらしい！

---

# 顔文字の改良

SVMの改良よりも先かもしれない

みんな平気で怒った顔文字を違う文脈で使う
あくまでも顔文字自体でなくどの文脈で使われるかを調べるべきか？

## 出て来て欲しい感情が出てこない

    <tw suk> <span>Ｒ友</span><em tak+suk+yor+yas>＼(^o^)／</em><span>友達</span><em tak+suk+yor+yas>＼(^o^)／</em><span suk>好き</span><em tak+suk+yor+yas>＼(^o^)／</em><span>照れたやろ</span><em ika+tak>(〃ω〃)？(笑) "(*´∀｀*)"</em> </tw>
    <tw> <span>虎吉ちゃんおかありで～す</span><em>＼(*⌒0⌒)ｂ♪ｵﾔｽﾐﾅｻ～ｲ.†ε('-'*)з  ─ﾟ+｡d(`ゝc_･´)ﾟ+｡─ｯ♪</em><conj>また</conj><span>明日～</span><em yor>（~▽~＠）♪♪♪☆</em> </tw>
    <tw> <em ika+tak>＼(･∀･｀*)／</em><span>「</span><span>ももんもー」</span><em ika>(っ´ﾟωﾟ｀c)ﾓｰ ←</em> </tw>
    <tw> <span>Ver.3発売まで10日を切りましたか。</span><em> ･･････</em><span>そろそろ銀子さんやさくやのスリーブをですね</span><em>･･････</em> </tw>
    <tw> <span>ＪＥＳＵＳ-GACKT←ちょーあがった！</span><em ika+tak>≡ ⊂( ^-^)⊃</em><span>ミュンヘンのライブバージョン</span><em tak+suk+yor+yas>((((^-^))))</em><span>ハァァン</span> </tw>
    <tw> <span>オモオモ</span><em tak+awa>Σ(´◎ω◎`)</em><span>肝心な自己紹介忘れてた！</span><span>チング達から最強ピョンテの名を頂い</span><conj>て</conj><span>おります！</span><span>ピョンテや妄想が暴走するピョンテ暴走族の頭</span><em ika+tak>ヾ(*´∀｀*)ﾉ</em><span>ちゃみたんのおちゃみが大好物で顔よりもまずそこを見ます♪悪しからず…</span> </tw>

## 出過ぎ

    <tw> <span>みーちゃん♥お誕生日おめでとう</span><em ika+tak+suk+yor>(≧▽≦)</em><span>♥♥5月にはみーちゃんと初対面、</span><span>夏には名古屋遊び行けたらいいなー</span><em iya+tak+suk+yor>(*´▽｀*)♥♥</em><span>これからもよろしくね♥ステキな25歳ライフを♥♥</span> </tw>
    <tw> <span>このタグで思い出した</span><conj>けど</conj><span>高校の時に友達とこういう話題になっ</span><conj>て</conj><span>、「</span><span>私は何が似合うと思う？</span><em iya+tak+suk+yor>？(*´ω`*)</em><span>」</span><span>って聞いたら「</span><span>フルートの足部管」</span><span>って言われ</span><conj>て</conj><em ika+iya+tak>（・ω・｀）</em><span>ってなった。</span><span>フルートやってた</span><conj>けども</conj><span>…</span><span>武器じゃない…</span> </tw>

まあ、自分のアノテートから辞書構築しなおせばいっか

---

素性に！の個数とか♥の個数はありか？

---

emem:41

    <tw> <span>お皿洗いし</span><conj>ながら</conj><span>ノリノリなりすぎ</span><conj>て</conj><span war>頭痛し</span><conj war>て</conj><span war>きた</span><em war>(笑)</em><conj yor>でも</conj><span yor>OwlCity好な人はきっと気に入っ</span><conj yor>て</conj><span yor>くれると思うんよね</span><em yor>(´^ω^｀)</em><span>Futuregirl,retrostyle-Ihatethisplace</span> </tw>

「でも」の前後での変化,
これは取れるようになったら自分としては大満足

###################
## 2014-01-13.mkd
# 顔文字辞書の増強

顔文字は完全に自分のアノテートからのみ作ることにした
DTAK採用してんだから未知のが出て来てもある程度は大丈夫
例えば口が省略されたパターンとか

    (^-^)
    (;-;)

が区別される程度のパラメタを探そう

| 条件             | ペナルティ |
|:----------------:|:-----------|
| 括弧の一致       |     +0     |
| 一致             |     +1     |
| 括弧とのギャップ |     +0     |
| ギャップ         |     -1     |

    assert(   sim( '(^_^)' , '(^-^)' )); // positive
    assert( ! sim( '(^_^)' , '(;_;)' )); // negative
    assert( ! sim( '(^-^)' , '(;_;)' ));
    assert(   sim( ';;'    , '(;_;)' ));

こんなこと書いてみた。

* これを用いてもう一度SVMを作り直すこと

## the number of icons them and filterd

### before filtered

dist [ 70159, 8077, 601, 85, 25, 14, 2, , , 1 ]
mean = 0.162162


### span when icon  > 1

dist [ , 13, 131, 125, 118, 82, 75, 60, 49, 25, 12, 9, 3, 2, 1, 1, 1, , , , 1, , , , , , 1 ]
mean 4.782792665726375


###################
## 2014-01-16.mkd
# F-score of ML-ask

順に Prec Recall : F

Independent:
    0.9333333333333333 0.03553299492385787 : 0.06845965770171149

Emoticon-1:
    0.9166666666666666 0.027918781725888325 : 0.0541871921182266

緩くした版が次。すなわち、yorタグがML-Askの中に含まれてるものもOKとしたもの。

Independent:
    { tru_pos: 28, fal_pos: 3, fal_neg: 366, tru_neg: 175 }
    0.9032258064516129 0.07106598984771574 : 0.13176470588235295

Emoticon-1:
    { tru_pos: 152, fal_pos: 46, fal_neg: 242, tru_neg: 132 }
    0.7676767676767676 0.38578680203045684 : 0.5135135135135135


###################
## 2014-01-22.mkd
# 顔文字の精度

crfsuiteをそのまま使うと

    cympfh@:detectIconCRF$ crfsuite learn --split=10 -x train.crf

    ***** Iteration #67 *****

    Loss: 171.030845
    Feature norm: 10.165830
    Error norm: 0.193921
    Active features: 26451
    Line search trials: 1
    Line search step: 1.000000
    Seconds required for this iteration: 0.013
    Performance by label (#match, #model, #ref) (precision, recall, F1):
        O: (1861, 1867, 1863) (0.9968, 0.9989, 0.9979)
        B: (23, 24, 25) (0.9583, 0.9200, 0.9388)
        I: (161, 163, 166) (0.9877, 0.9699, 0.9787)
    Macro-average precision, recall, F1: (0.980950, 0.962935, 0.971785)
    Item accuracy: 2045 / 2054 (0.9956)
    Instance accuracy: 58 / 63 (0.9206)

    L-BFGS terminated with the stopping criteria
    Total seconds required for training: 0.986

training data は 632 ツイートで、全部会わせて 272 の em-tag を持つ

# Baselinesの正解率

|        | Prec               | Recall             | F1                 |
|:-------|:-------------------|--------------------|--------------------|
| k=0(素)| 0.9032258064516129 | 0.0710659898477157 | 0.1317647058823530 |
| k =  1 | 0.7676767676767676 | 0.3857868020304568 | 0.5135135135135135 |
| k =  2 | 0.7510373443983402 | 0.4593908629441624 | 0.5700787401574803 |
| k =  3 | 0.7372013651877133 | 0.5482233502538071 | 0.6288209606986899 |
| k =  4 | 0.735202492211838  | 0.5989847715736041 | 0.6601398601398601 |
| k =  5 | 0.7251461988304093 | 0.6294416243654822 | 0.6739130434782609 |
| k =  6 | 0.7295774647887324 | 0.6573604060913706 | 0.691588785046729  |
| k =  7 | 0.7342465753424657 | 0.6802030456852792 | 0.7061923583662715 |
| k =  8 | 0.7371273712737128 | 0.6903553299492385 | 0.7129750982961991 |
| k =  9 | 0.7351351351351352 | 0.6903553299492385 | 0.712041884816754  |
| k = 10 | 0.7351351351351352 | 0.6903553299492385 | 0.712041884816754  |
| k = 11 | 0.7351351351351352 | 0.6903553299492385 | 0.712041884816754  |

###################
## 2014-01-23.mkd
# SVMにおける全体の感情という素性の効き方

自分のSVMは11(ホントは9)の素性を用いる

| Prec   | 320 / 365 = 0.8767123287671232 |
| Recall | 320 / 370 = 0.8648648648648649 |
| F1     | 0.8707482993197279             |

全体の感情を抜くと実際精度は悪くなる

| Prec   | 335 / 403 = 0.8312655086848635 |
| Recall | 335 / 370 = 0.9054054054054054 |
| F      | 0.8667529107373868             |

まあほんのちょっとか

###################
## 2014-01-24.mkd
# 多値分類に対応した

性能絶対落ちると思ったけどそんなことなかった

one-vs-rest法を使います
pairwise法とか時間的に無理でしょ絶対

| Prec   | 363 / 438 = 0.8287671232876712 |
| Recall | 363 / 394 = 0.9213197969543148 |
| F      | 0.8725961538461539             |

性能落ちてないな！よし

忘れてるけど、そもそものデータを制限してたのが上。
制限しないと下のように。

| Prec   | 63 / 68 = 0.9264705882352942  |
| Recall | 63 / 223 = 0.2825112107623318 |
| F      | 0.43298969072164945           |

まあそりゃ顔文字を素性にしてんだからな

[[2014-01-30]] だとちょっと性能が上がってるので、こちらも参照

###################
## 2014-01-28.mkd
# ML-Ask icons-8 がアノテートするタグの数 (平均)

| area             | counts | with | num of tags |
| :--------------- | ----:  | :-:  | --------    |
| true-positive    | 272    |      | 3.41544     |
| false-positive   |  97    |      | 3.16495     |
| false-negative   | 122    |      | 1.06557     |
| true-negative    |  81    |      | 1.28395     |

たくさんアノテートした時のがpositiveとして使われるのはこれは私のせい
でも たくさん出すほど true-positive になるのはやはり当然で
平均して3.4のタグから一つ出さないと行けないのだから
やはりそのままは使えない

###################
## 2014-01-30.mkd
# 多値分類の性能 (ベースラインとSVM)

## ベースライン

```
    null
    0.17365269461077845 0.3411764705882353 : 0.2301587301587302
    { tru_pos: 1,
      fal_pos: 1,
      fal_neg: 3.0714285714285716,
      tru_neg: 3.2406876790830945 }
    { tru_pos: 29, fal_pos: 138, fal_neg: 56, tru_neg: 349 }

    yor
    0.7371273712737128 0.6903553299492385 : 0.7129750982961991
    { tru_pos: 3.4154411764705883,
      fal_pos: 3.1649484536082473,
      fal_neg: 1.0655737704918034,
      tru_neg: 1.2839506172839505 }
    { tru_pos: 272, fal_pos: 97, fal_neg: 122, tru_neg: 81 }

    ai
    0.29914529914529914 0.4375 : 0.3553299492385787
    { tru_pos: 2.7714285714285714,
    fal_pos: 3.3902439024390243,
      fal_neg: 1.7555555555555555,
      tru_neg: 2.478048780487805 }
    { tru_pos: 35, fal_pos: 82, fal_neg: 45, tru_neg: 410 }

    ika
    0.023668639053254437 1 : 0.046242774566473986
    { tru_pos: 2,
      fal_pos: 3.036363636363636,
      fal_neg: NaN,
      tru_neg: 2.3846153846153846 }
    { tru_pos: 4, fal_pos: 165, fal_neg: 0, tru_neg: 403 }

    odo
    0 0 : 0
    { tru_pos: NaN,
      fal_pos: 5.5,
      fal_neg: 2.5,
      tru_neg: 2.560070671378092 }
    { tru_pos: 0, fal_pos: 2, fal_neg: 4, tru_neg: 566 }

    haj
    0.06451612903225806 0.4 : 0.1111111111111111
    { tru_pos: 3,
      fal_pos: 4.413793103448276,
      fal_neg: 3.3333333333333335,
      tru_neg: 2.4646840148698885 }
    { tru_pos: 2, fal_pos: 29, fal_neg: 3, tru_neg: 538 }
```


## SVM

```
    null
    Prec   | 63 / 169 = 0.3727810650887574
    Recall | 63 / 85 = 0.7411764705882353
    F = 0.49606299212598426
    yor
    Prec   | 352 / 391 = 0.9002557544757033
    Recall | 352 / 394 = 0.8934010152284264
    F = 0.8968152866242037
    ai
    Prec   | 12 / 12 = 1
    Recall | 12 / 80 = 0.15
    F = 0.2608695652173913
    ika
    Prec   | 0 / 0 = NaN
    Recall | 0 / 4 = 0
    F = NaN
    odo
    Prec   | 0 / 0 = NaN
    Recall | 0 / 4 = 0
    F = NaN
    haj
    Prec   | 0 / 0 = NaN
    Recall | 0 / 5 = 0
    F = NaN
```

よかったベースラインもひどいものだった

これは2014/01/26 にもあるけど

|      |     |
|:-----|----:|
| null | 85  |
| yor  | 394 |
| ai   | 80  |
| ika  | 4   |
| odo  | 4   |
| haj  | 5   |


###################
## 2014-02-25.mkd
# CRF でもやってみよ

## with CRFsuite

```
        Performance by label (#match, #model, #ref) (precision, recall, F1):

        yor: (30, 48, 30) (0.6250, 1.0000, 0.7692)
        null: (0, 5, 9) (0.0000, 0.0000, 0.0000)
        ai: (0, 0, 10) (0.0000, 0.0000, 0.0000)
        haj: (0, 0, 2) (0.0000, 0.0000, 0.0000)
        odo: (0, 0, 0) (******, ******, ******)
        ika: (0, 0, 2) (0.0000, 0.0000, 0.0000)
        Macro-average precision, recall, F1: (0.104167, 0.166667, 0.128205)
```

ただしこれは、

```
    token = text | icon | conj
    pos = yor | war | ... | yor+war | ...
          \/ 接続詞用法
```

などとしてる

```
    yor	w[0]=text	w[1]=conj	w[2]=text	w[0]|w[1]=text|conj	pos[0]=null	pos[1]=null	pos[2]=null	pos[0]|pos[1]=null|null	pos[1]|pos[2]=null|null	pos[0]|pos[1]|pos[2]=null|null|null	__BOS__
    yor	w[-2]=text	w[-1]=conj	w[0]=text	w[1]=conj	w[2]=text	w[-1]|w[0]=conj|text	w[0]|w[1]=text|conj	pos[-2]=null	pos[-1]=null	pos[0]=null	pos[1]=null	pos[2]=yor	pos[-2]|pos[-1]=null|null	pos[-1]|pos[0]=null|null	pos[0]|pos[1]=null|null	pos[1]|pos[2]=null|yor	pos[-2]|pos[-1]|pos[0]=null|null|null	pos[-1]|pos[0]|pos[1]=null|null|null	pos[0]|pos[1]|pos[2]=null|null|yor
    yor	w[-2]=text	w[-1]=conj	w[0]=text	w[1]=icon	w[2]=text	w[-1]|w[0]=conj|text	w[0]|w[1]=text|icon	pos[-2]=null	pos[-1]=null	pos[0]=yor	pos[1]=ika+iya+tak	pos[2]=null	pos[-2]|pos[-1]=null|null	pos[-1]|pos[0]=null|yor	pos[0]|pos[1]=yor|ika+iya+tak	pos[1]|pos[2]=ika+iya+tak|null	pos[-2]|pos[-1]|pos[0]=null|null|yor	pos[-1]|pos[0]|pos[1]=null|yor|ika+iya+tak	pos[0]|pos[1]|pos[2]=yor|ika+iya+tak|null
```

でも他に分からないから。
事例数少ないのに感情の組み合わせを一つにしてたら足りないだろうから、
荒くこんなことしてみる。すなわち、感情の組み合わせは次の3パターン

- null
- yor を含む
- 含まない

```
         yor: (30, 50, 30) (0.6000, 1.0000, 0.7500)
         null: (3, 3, 9) (1.0000, 0.3333, 0.5000)
         ai: (0, 0, 10) (0.0000, 0.0000, 0.0000)
         haj: (0, 0, 2) (0.0000, 0.0000, 0.0000)
         odo: (0, 0, 0) (******, ******, ******)
         ika: (0, 0, 2) (0.0000, 0.0000, 0.0000)
         Macro-average precision, recall, F1: (0.266667, 0.222222, 0.208333)
```

ラベルにIOB2を導入したのが [[2014-03-04]] こちらも参照

###################
## 2014-03-04.mkd
# CRF with IOB2 tag

先日アドバイス頂いた通り、CRFにおいてターゲットにIOB2を取り入れてみる。
つまり、

    Label = A | B | C | ...

を

    Label = A-B | A-I | B-B | B-I | C-B | ...

にする。結果は


    Seconds required for this iteration: 0.010
    Performance by label (#match, #model, #ref) (precision, recall, F1):
        yor-B: (5, 10, 7) (0.5000, 0.7143, 0.5882)
        yor-I: (23, 40, 23) (0.5750, 1.0000, 0.7302)
        null-B: (1, 1, 3) (1.0000, 0.3333, 0.5000)
        null-I: (2, 2, 6) (1.0000, 0.3333, 0.5000)
        ai-B: (0, 0, 3) (0.0000, 0.0000, 0.0000)
        ai-I: (0, 0, 7) (0.0000, 0.0000, 0.0000)
        haj-B: (0, 0, 1) (0.0000, 0.0000, 0.0000)
        haj-I: (0, 0, 1) (0.0000, 0.0000, 0.0000)
        odo-B: (0, 0, 0) (******, ******, ******)
        odo-I: (0, 0, 0) (******, ******, ******)
        ika-B: (0, 0, 1) (0.0000, 0.0000, 0.0000)
        ika-I: (0, 0, 1) (0.0000, 0.0000, 0.0000)
    Macro-average precision, recall, F1: (0.256250, 0.198413, 0.193200)


取り入れる前の [[2014-02-25]] より部分的に悪くなってる。
あんまりおもしろい結果ではなかった。

###################
## 2014-04-16.mkd
# CVS with linear kernel

rbf kernel で 87.3 % であったあのデータセットで
今度は線形カーネルを適用すると

## null
| Prec   | 18 / 82 = 0.21951219512195122 |
| Recall | 18 / 85 = 0.21176470588235294 |
| F      | 0.21556886227544908           |
## yor
| Prec   | 365 / 490 = 0.7448979591836735 |
| Recall | 365 / 394 = 0.9263959390862944 |
| F      | 0.82579185520362               |
## ai
| Prec   | 0 / 0 = NaN |
| Recall | 0 / 80 = 0  |
| F      | NaN         |
## ika
| Prec   | 0 / 0 = NaN |
| Recall | 0 / 4 = 0   |
| F      | NaN         |
## odo
| Prec   | 0 / 0 = NaN |
| Recall | 0 / 4 = 0   |
| F      | NaN         |
## haj
| Prec   | 0 / 0 = NaN |
| Recall | 0 / 5 = 0   |
| F      | NaN         |

###################
## 2014-04-22.mkd
# meeting

* 大きなコーパスから
* テストデータ、顔文字辞書を新しく作る

- コーパス作る
- サーベイが足りない
    + 特にFine-Grained について (pos/neg, emotions なんでも)
- 実験のシナリオ
    - 評価方法
        + 系列ラベリングで、範囲を見るための実験の評価方法 (厳密な方法、ゆるい方法) (サーベイ)
        + AAA に対して A_A はどうするか、みたいな (span vs. unit)
- 昔のコーパス、忘れた状態でもっかい振ってみる
- ゆくゆくは音響から学習 & 音響での評価
- 読んでない参考文献は読む。[11]とか
    + 2,3年のACL、言語処理全国大会くらい見る
    + semeval 2013
        - tweetをidで引用してる

###################
## 2014-05-01.mkd
# アノテートの作業をする

忘れてたかもしれないけど、タグ一覧: yor null ai haj odo ika

ただし昔書いたやつを対象にすることで一致度を見ることも同時におこなう

プログラムについては
まだユニットに区切るところまでで力尽きてる

---

```xml
<tweet>
  <text>明日はLIVESUPERNOVAvol.68</text>
  <icon>(^^)</icon>
  <text>赤い公園、</text>
  <text>ammoflight、</text>
  <text>HelloSleepwalkersが出演する番組主催の無料ライブ！</text>
  <text>開演前にはたくみさんのDJもある</text>
  <conj>ので</conj>
  <text>、</text>
  <text>お早めに</text>
  <icon>(^-^)/</icon>
  <text>...</text>
</tweet>
```

顔文字のために全部 yor にした

```
<tweet>
  <text>このタグで思い出した</text>
  <conj>けど</conj>
  <text>高校の時に友達とこういう話題になっ</text>
  <conj>て</conj>
  <text>、「</text>
  <text>私は何が似合うと思う？</text>
  <icon>？(*´ω`*)</icon>
  <text>」</text>
  <text>って聞いたら「</text>
  <text>フルートの足部管」</text>
  <text>って言われ</text>
  <conj>て</conj>
  <icon>（・ω・｀）</icon>
  <text>ってなった。</text>
  <text>フルートやってた</text>
  <conj>けども</conj>
  <text>…</text>
  <text>武器じゃない…</text>
</tweet>
```

まず、「」の中身をどうするか。
今回はエスパーした。
それと、
「´・ω・｀)ってなった」
のように顔文字が言語情報になってる場合
これはムリだ

---

アノテートがやっと終わった
昔のアノテーションとの比較も合わせて

https://github.com/cympfh/tweets-emotions-annotations/
https://github.com/cympfh/tweets-emotions-annotations/blob/master/output

とした

###################
## 2014-05-06.mkd
`git/sotu` 進めてた。
- `detect-icon`の虫取り
- `unit`の虫取り
- `conj`作った

バグしかいなかった

`detect-icon` -> `unit`
だけやってくれる`doall`なるスクリプト書いといたから、
素のツイートデータから
xmlもどきまで自動生成できる

###################
## 2014-05-08.mkd
# アノテートのガイドライン (html), meeting

# アノテートのガイドライン (html)

https://www.dropbox.com/sh/pg0a0g48520x7yv/lyvZZBJhFs

見れるだろうか
あんまり見れないっぽいので、素htmlとpngだけにしよう

# u08.txt

db://tw/u08.txt
db://tw/hand08.txt

人手アノテーションした。

| null | yor | ai | odo | ika | haj |
| 157  | 53  | 9  | 5   | 0   | 0   |

# 前のが、(new)

| null | yor | ai | odo | ika | haj |
| 122  | 237 | 40 | 14  | 2   | 9   |

# total

| null | yor | ai | odo | ika | haj |
| 279  | 237 | 49 | 19  | 2   | 9   |

# さらに
# u12.txt

db://tw/u12.txt
db://tw/hand12.txt

| null | yor | ai | odo | ika | haj |
| 169  | 72  | 4  | 4   | 1   | 0   |

# u16.txt

db://tw/u16.txt
db://tw/hand16.txt

(134,41,12,10,1,0)

# meeting

「遊んでくれる」
「お待ちしています」
みたいなのを今は区切ってるけど、後ろを見ると一つの文節とできる。

## tool

nullの背景色かなんか。

## 追加アノテーション

- やっぱり怒りは欲しい。
- 怒ってそうな表現で検索→ハッシュタグを集める

ターゲットを絞ること。

## paste コマンド

###################
## 2014-05-20.mkd
# ミーティング

検索ワードというのは、
素性でフィルタしてるから
ホントはハッシュタグがいい．

- SVMを多値にする
- 全体でcatしてバランスとる
- #怒り タグ
- 「イライラ」を含まないスパンだけで実験するというのもいい
  + 別々にして比較する


###################
## 2014-05-25.mkd
## svm-cross-valid

2014年  5月 25日 日曜日 12:12:48 JST

卒論と同じ特徴量にしたはずの、二値SVM
SVMには`libsvm`を用いた．
`grid.py` 使って、それぞれF1を最適化した結果が次．

### 08 null
precision = 0.761194
recall = 0.987097
F1 value = 0.859551

### 08 yor
precision = 1
recall = 0.159091
F1 value = 0.27451

### 08 ika
precision = -nan
recall = 0
F1 value = -nan

### emem null
precision = 0.693878
recall = 0.306306
F1 value = 0.425

### emem yor
precision = 0.75
recall = 0.681223
F1 value = 0.713959

### emem ika
precision = -nan
recall = 0
F1 value = -nan

### ira200 null
precision = 0.734914
recall = 0.890339
F1 value = 0.805195

### ira200 yor
precision = 0.7
recall = 0.21875
F1 value = 0.333333

### ira200 ika
precision = 1
recall = 0.105263
F1 value = 0.190476

`grid.py`も完璧じゃなくて、
`08 yor`についてだけは、

`-c 32 -g 0.0078 ` の時に、

### 08 yor
precision = 0.769231
recall = 0.227273
F1 value = 0.350877

でもっと良い

---

`libsvm`で多値とかわからんし、
結局結局 `npm` の [svm](https://www.npmjs.org/package/svm) を使うのでした．．．

多値も簡単に対応できた．
結果は、/git/svm/results.md としよう．

```
$ ./test/cross

08
null: 0.6666666666666666 1 0.8
yor: 1 0.25 0.4
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN NaN NaN
haj: NaN NaN NaN
emem
null: 0.6 0.23076923076923078 0.3333333333333333
yor: 0.6666666666666666 1 0.8
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN NaN NaN
haj: NaN NaN NaN
ira200
null: 0.5306122448979592 0.7878787878787878 0.6341463414634146
yor: 0 0 0
ai: 0 0 0
odo: NaN NaN NaN
ika: NaN 0 NaN
haj: 0 NaN NaN
```

嘘10交差検定 (ホントは10の平均とらないといけないけど1しかやってないや) であることに注意．
`emem/yor` が卒論くらいの数字が出たので安心．

しかしながら、せっかくの、`ira200`とかで`ika`が全然出てないぞ

パラメータの調整をしてから、もうちょっと進めよう．

---

それぞれのデータセットについてパラメータ調整して、それぞれの最大をとる．
ただし6つの感情それぞれについてF1スコアだしてどうやって最大をとるべきかはわからないから
そこは雰囲気だ．

```
$ ./count.exe < ~/Dropbox/tw/08/h
(157,53,9,5,4,0)
$ ./count.exe < ~/Dropbox/tw/emem/h
(122,237,40,14,2,9)
$ ./count.exe < ~/Dropbox/tw/ira200/h
(417,80,91,14,74,0)
```

## 08 ( C=0.8, sigma=0.8 )
null: 0.6666666666666666 1 0.8
yor: 1 0.25 0.4
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN NaN NaN
haj: NaN NaN NaN

## emem ( C=0.8, sigma=0.8 )
null: 0.6 0.23076923076923078 0.3333333333333333
yor: 0.6666666666666666 1 0.8
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN NaN NaN
haj: NaN NaN NaN

## ira200 ( C=1.0, sigma=0.5 )
null: 0.5416666666666666 0.7878787878787878 0.6419753086419753
yor: 0 0 0
ai: 0 0 0
odo: NaN NaN NaN
ika: NaN 0 NaN
haj: 0 NaN NaN

---

```
$ cat 08 12 16 emem ira200 > cat
$ ./count.exe < ~/Dropbox/tw/cat/h
(999,483,156,47,82,9)
```

## cat ( C=0.8, sigma=0.8 )
null: 0.6363636363636364 0.9578947368421052 0.7647058823529411
yor: 0.5555555555555556 0.3225806451612903 0.4081632653061224
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN 0 NaN
haj: NaN NaN NaN


---

バランスを取りましょう．
ツイートを追加していって、感情が50以下のものが増えない場合は追加しない．

一つのツイートをバラバラにはしたくなかったので、このようなことをすると、

```
$ ./count.exe < ~/Dropbox/tw/cat_balanced/h
(174,112,67,47,50,9)
```

## cat_balanced ( C=0.8, sigma=0.8)
null: 0.1111111111111111 0.058823529411764705 0.07692307692307693
yor: 1 0.21739130434782608 0.35714285714285715
ai: 0 NaN NaN
odo: NaN 0 NaN
ika: 0.045454545454545456 1 0.08695652173913043
haj: 0 NaN NaN

## cat_balanced2
null: 0.3333333333333333 0.14285714285714285 0.2
yor: 0.25 0.3333333333333333 0.2857142857142857
ai: 0.3333333333333333 0.8571428571428571 0.48
odo: NaN 0 NaN
ika: NaN 0 NaN
haj: 0 NaN NaN

ガチ３交差検定 ( C=0.8, sigma=0.8 )

## 08
null: 0.7311320754716981 1 0.8446866485013624
yor: 0.5 0.022727272727272728 0.043478260869565216
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN 0 NaN
haj: NaN NaN NaN

## emem
null: 0.5277777777777778 0.17117117117117117 0.2585034013605442
yor: 0.5922619047619048 0.868995633187773 0.7044247787610619
ai: 0 0 0
odo: 0 0 0
ika: 0 0 0
haj: 0 0 0

## ira200
null: 0.7010526315789474 0.8694516971279374 0.7762237762237763
yor: 0 0 0
ai: NaN 0 NaN
odo: NaN 0 NaN
ika: NaN 0 NaN
haj: 0 NaN NaN

## cat
null: 0.6669354838709678 0.8797872340425532 0.7587155963302753
yor: 0.5888324873096447 0.27423167848699764 0.37419354838709673
ai: 0 0 0
odo: NaN 0 NaN
ika: 0 0 0
haj: 0.026845637583892617 0.4444444444444444 0.05063291139240506

## cat_balanced
null: 0.5695652173913044 0.6218354430379747 0.5945537065052949
yor: 0.7931034482758621 0.46464646464646464 0.5859872611464969
ai: 0.3082039911308204 0.6813725490196079 0.42442748091603055
odo: 0.3254437869822485 0.31976744186046513 0.3225806451612903
ika: 0.8372093023255814 0.20930232558139536 0.33488372093023255
haj: 0.9259259259259259 0.6944444444444444 0.7936507936507936
04:51:11 sotu$

## cat_balanced2
null: 0.3263888888888889 0.42727272727272725 0.3700787401574803
yor: 0.30952380952380953 0.21311475409836064 0.2524271844660194
ai: 0.1388888888888889 0.09803921568627451 0.1149425287356322
odo: 0.3333333333333333 0.023255813953488372 0.043478260869565216
ika: 0.056179775280898875 0.11627906976744186 0.07575757575757576
haj: 0 0 0



###################
## 2014-05-26.mkd
# 定例ミーティング

6SVM の各スコアをさらに素性にして、

テストデータと、学習データわけること．
テストデータは最後の最後までみない．

学習データは自分で作ってもいいけど
テストデータは自分を除いた人間がつけるのが本当．

ML-Askでどのくらい結果が落ちているのか．
ML-Askの結果を人間に置き換えて、
顔文字もそうして、
どれくらい推定できるか．
それが、upper bound になる．

## 教師ありデータが本当は欲しい．

ハッシュタグ -> 感情
があればいい．
少数派、ノイズはあってもいい．

定常的にその感情であるようなハッシュタグ
野球みたいなバーストがあるのは望ましくない

## 辞書の自動生成を目標にずらす???

1. ツイートが流れる
1. キーワード
1. ハッシュタグ検出
1. ツイート集まる→辞書ができる

### サーベイ

鍛冶さん
辞書の自動構築

他に灘本さんの
db://pdf/E6-2.pdf

NB. 参考文献もあたること．

# ポスターの文字フォントは `45pt`


###################
## 2014-06-08.mkd
# 進捗つくらなくっちゃ

[二つの文字列の類似度 - ktr_skmtの日記](http://d.hatena.ne.jp/ktr_skmt/20111214/1323835913)
ところで，これ便利そうだ

## 前回までのあらすじ

- 空白
- !！
- ー〜-

という表層文字を加えた．

balanced corpus を撮り直して、`cat_balanced3` とした．

### cat

(999,487,156,47,82,9)

null: 0.7150786308973173 0.8223404255319149 0.7649678377041068
yor: 0.46124031007751937 0.28132387706855794 0.3494860499265786
ai: 0.3333333333333333 0.01652892561983471 0.031496062992125984
odo: 0.125 0.023255813953488372 0.0392156862745098
ika: 0 0 0
haj: 0.0330188679245283 0.7777777777777778 0.06334841628959277

### cat_balanced3

(118,68,67,47,50,9)

null: 0.3263157894736842 0.5636363636363636 0.41333333333333333
yor: 0.09523809523809523 0.09836065573770492 0.09677419354838711
ai: 0.34615384615384615 0.17647058823529413 0.23376623376623376
odo: 0.2916666666666667 0.16279069767441862 0.208955223880597
ika: 0.14285714285714285 0.046511627906976744 0.07017543859649122
haj: NaN 0 NaN

# `libsvm` を使います

デフォルトで多値に対応していた．
でも結果が精度ででしか教えてくれない．
あとで結果を比較しよう．
そのために、クロスバリデーションすることをやめて、
学習用とテスト用完全に分けている．

```bash
cat it.train | sort -R > it.shuffled
lines=`wc -l it.shuffled`
head -n $(( $lines * 9 / 10 )) it.shuffled > it.train
head -n $(( $lines * 1 / 10 )) it.shuffled > it.test
```

## 表層何もなし

| cat      | Accuracy = 80.625% (129/160) (classification) |
| balanced | Accuracy = 74.1935% (23/31) (classification)  |

## 表層全部

学習に出てきた文字を全部追加すると、
646文字追加されて、SVMへの入力は、714次元となった


詳細には見ていないけれど

| cat      | Accuracy = 87.5% (140/160) (classification) |
| balanced | Accuracy = 100% (31/31) (classification)    |

「イライラ」のターゲットを学習からもテストからも覗くと

| cat      | Accuracy = 85% (136/160) (classification)    |
| balanced | Accuracy = 96.7742% (30/31) (classification) |

ちょっと落ちてるけど人間味ある性能だ

// AccじゃなくてF1-scoreがあったほうがいいだろう、本当は

先に [LIBSVMの特徴量の重みを見る - LIBSVMのモデルの読み方 - 唯物是真 @Scaled_Wurm](http://sucrose.hatenablog.com/entry/2013/07/10/223952) を使って、

`balanced`に対する結果をベタ貼りする．
{{{
50 -27.8812582836
244 -20.0520670117
182 -16.886084596
44 -16.679789583
49 -14.8436367105
238 14.5004222017
168 13.3448873473
52 -12.5624574293
63 10.8241266759
209 -10.2455500226
306 9.90425554177
681 -9.6
43 -9.35958020502
248 9.19005843791
216 -8.88314803584
178 -8.40672343475
205 -8.20637250669
206 8.1039151257
68 7.28590807509
239 7.14534207071
235 -6.84362839011
54 -6.4
691 -6.4
197 -6.12991542074
169 5.5492318987
48 -5.48132869508
199 -5.48115375404
45 -5.47979062206
46 -5.47978958296
237 -5.4474111582
185 -5.24230552419
183 -5.17107884742
191 4.86981039871
114 -4.8
211 4.59657262152
228 -4.56104804434
230 -4.32356544517
187 -4.08584774505
215 3.9824651086
304 3.91531655927
305 -3.88125846124
391 -3.88125845266
326 -3.88125845079
180 -3.88114876824
59 -3.88111603374
177 3.81477771188
301 3.67644462987
226 -3.64391749179
243 -3.64083970344
61 3.61192787474
299 3.47131739478
71 -3.2
101 -3.2
115 -3.2
122 -3.2
126 -3.2
129 -3.2
163 -3.2
164 -3.2
165 -3.2
166 -3.2
394 -3.2
526 -3.2
606 -3.2
229 3.03493458749
233 -2.96111812099
204 2.7916792195
258 2.75916134282
607 2.75772755819
267 2.75769350604
58 2.75769245648
647 2.75769113534
319 2.75762339217
85 2.7575513825
276 2.75636325792
449 2.75630379397
242 2.55150013177
236 -2.45459451725
66 -2.28245753496
390 -2.28132901678
271 -2.28125895687
2 -2.28125847337
8 -2.28125847337
14 -2.28125847337
20 -2.28125847337
26 -2.28125847337
32 -2.28125847337
38 -2.28125847337
214 -2.28125847112
218 -2.28125846124
257 -2.27979062206
596 -2.2797895831
203 2.18021422123
172 2.07773068391
189 2.07629213198
269 -2.04237638769
65 1.8416713022
260 1.84041979752
173 1.83903178735
186 1.83903009657
217 1.83901128035
629 1.83895197493
552 1.83895196848
697 1.83895195449
365 1.83895091814
64 1.83888236041
565 1.83888140934
51 1.83756243523
627 1.83756225746
445 1.83756017092
489 1.83754238346
247 1.83754238346
286 1.83749234311
356 1.83748309615
259 1.83748175691
525 1.83748175691
539 1.83747342449
444 1.83747183745
499 1.83747183745
219 1.83741346352
84 1.83741163992
231 -1.80483412802
208 1.63710172011
74 -1.6
94 -1.6
104 -1.6
108 -1.6
111 -1.6
113 -1.6
118 -1.6
121 -1.6
123 -1.6
124 -1.6
125 -1.6
127 -1.6
128 -1.6
130 -1.6
132 -1.6
137 -1.6
139 -1.6
140 -1.6
143 -1.6
174 -1.6
188 -1.6
192 -1.6
198 -1.6
200 -1.6
221 -1.6
268 -1.6
270 -1.6
273 -1.6
296 -1.6
315 -1.6
317 -1.6
322 -1.6
345 -1.6
384 -1.6
393 -1.6
395 -1.6
396 -1.6
397 -1.6
412 -1.6
413 -1.6
416 -1.6
417 -1.6
418 -1.6
423 -1.6
425 -1.6
426 -1.6
432 -1.6
436 -1.6
447 -1.6
463 -1.6
465 -1.6
466 -1.6
468 -1.6
474 -1.6
476 -1.6
477 -1.6
495 -1.6
503 -1.6
543 -1.6
566 -1.6
571 -1.6
590 -1.6
592 -1.6
630 -1.6
637 -1.6
653 -1.6
667 -1.6
692 -1.6
694 -1.6
320 1.3952705981
201 1.39516626156
467 1.39369806169
288 -1.36245810264
265 -1.36245761654
225 -1.33120348767
184 -1.32965190721
223 1.15780229505
196 1.15769300801
207 1.15755250422
193 -1.08958539074
213 0.989899908172
56 0.983218381171
387 0.920210426119
343 0.920210426119
344 0.920210426119
501 0.920210426119
545 0.920210426119
624 0.920210426119
661 0.920210426119
703 0.920210426119
705 0.920210426119
709 0.920210426119
411 0.920210417038
522 0.920210417038
347 0.920210416897
544 0.920210414754
635 0.920210311637
536 0.920209378442
331 0.92020937843
357 0.92020937843
364 0.92020937843
478 0.92020937843
484 0.92020937843
532 0.92020937843
575 0.92020937843
604 0.92020937843
638 0.92020937843
656 0.92020937843
668 0.92020937843
674 0.92020937843
332 0.920209378403
654 0.920209378403
508 0.920209377948
662 0.920209377948
224 0.920209377945
283 0.920209377945
657 0.920209377938
279 0.920209371398
290 0.920209371398
292 0.920209371398
385 0.920209371398
452 0.920209371398
547 0.920209371398
530 0.920209367416
650 0.920209367416
420 0.918831472385
559 0.918821360561
623 0.918821360561
642 0.918821360561
414 0.918820721094
351 0.91882071879
406 0.91882071879
408 0.91882071879
440 0.91882071879
492 0.91882071879
550 0.91882071879
562 0.91882071879
369 0.918820718136
666 0.918820718136
3 0.918800854231
9 0.918800854231
15 0.918800854231
21 0.918800854231
27 0.918800854231
33 0.918800854231
39 0.918800854231
401 0.918800854231
78 0.918741551604
309 0.918741551604
80 0.91874155158
435 0.91874155158
459 0.91874155158
262 0.91874154881
330 0.91874154881
457 0.91874154881
608 0.91874154881
289 0.918741548803
293 0.918741548803
372 0.918741548803
673 0.918741548803
310 0.918741547344
485 0.918741547344
518 0.918741547344
649 0.918741547344
346 0.918741542365
374 0.918741540197
658 0.918741540197
676 0.918741540197
487 0.918741540197
507 0.918741540197
516 0.918741540197
527 0.918741540197
600 0.918741540197
659 0.918741540197
598 0.918741538665
628 0.918741538665
664 0.918741538665
612 0.91874153843
660 0.91874153843
389 0.918741536376
338 0.918741534989
430 0.918741534989
498 0.918741534989
368 0.918741529231
399 0.918741529231
553 0.918741529231
563 0.918741529231
652 0.918741529231
350 0.918741529229
386 0.918741529229
433 0.918741529229
577 0.918741529229
241 0.918741529228
583 0.918741529228
696 0.918741528372
698 0.918741528372
700 0.918741528372
704 0.918741528372
194 0.918741526625
515 0.918741526625
453 0.918741439613
509 0.918741439613
275 0.918741043128
272 0.918741043128
291 0.918741043128
407 0.918740216713
519 0.918740216713
610 0.918740216713
620 0.918739265048
631 0.91867713303
617 0.918672570263
284 0.918672143066
584 0.918671726588
167 0.918671304924
220 0.918671304924
254 0.918671304924
488 0.918671304924
493 0.918671304924
512 0.918671304924
5 0.918670983217
11 0.918670983217
17 0.918670983217
23 0.918670983217
29 0.918670983217
35 0.918670983217
41 0.918670983217
337 0.918670983217
529 0.918670983217
556 0.918670983217
579 0.918670983217
618 0.918670983217
266 0.918670982544
382 0.918670982544
419 0.918670088316
421 0.918670088316
506 0.918670088316
534 0.918670088316
591 0.918670088316
615 0.918670088316
640 0.918670088316
86 0.918670088316
87 0.918670088316
176 -0.88590342362
195 0.749382146925
75 -0.681329911684
76 -0.681329911684
352 -0.681329911684
581 -0.681329911684
672 -0.681329911684
400 -0.681329016783
434 -0.681329016783
438 -0.681328273412
234 -0.681327429723
240 -0.681259783287
619 -0.681259783287
298 -0.681258956872
285 -0.681258470771
376 -0.681258470769
398 -0.681258470769
323 -0.681258463624
669 -0.681258461335
252 -0.681258461239
287 -0.681258452656
609 -0.681258452656
55 -0.681258450792
311 -0.68125844842
62 -0.681199145769
446 -0.681199145769
540 -0.681199145769
568 -0.681199145769
578 -0.681153762648
282 -0.679790622062
316 -0.679790622062
537 -0.679790622062
594 -0.679790622052
520 -0.679790621558
370 -0.679789585246
255 -0.679789582962
295 -0.679789582962
572 -0.679789582962
443 -0.679789573881
277 -0.679789573881
294 -0.679789573881
371 -0.679789573881
212 -0.576072979465
147 0.476444614189
1 0.443786635927
7 0.443786635927
13 0.443786635927
19 0.443786635927
25 0.443786635927
31 0.443786635927
37 0.443786635927
210 -0.369859122184
471 0.240419795468
687 0.238951974928
175 0.237693422614
274 0.237542401574
601 0.237483249316
300 0.237471836775
190 0.237418849473
569 0.237412532425
521 0.237344296851
47 -1.11022302463e-15
53 -1.11022302463e-15
57 -1.11022302463e-15
72 -1.11022302463e-15
79 -1.11022302463e-15
82 -1.11022302463e-15
83 -1.11022302463e-15
91 -1.11022302463e-15
93 -1.11022302463e-15
95 -1.11022302463e-15
97 -1.11022302463e-15
98 -1.11022302463e-15
99 -1.11022302463e-15
102 -1.11022302463e-15
103 -1.11022302463e-15
105 -1.11022302463e-15
106 -1.11022302463e-15
107 -1.11022302463e-15
117 -1.11022302463e-15
120 -1.11022302463e-15
148 -1.11022302463e-15
171 -1.11022302463e-15
179 -1.11022302463e-15
181 -1.11022302463e-15
202 -1.11022302463e-15
222 -1.11022302463e-15
227 -1.11022302463e-15
232 -1.11022302463e-15
249 -1.11022302463e-15
250 -1.11022302463e-15
251 -1.11022302463e-15
253 -1.11022302463e-15
256 -1.11022302463e-15
261 -1.11022302463e-15
263 -1.11022302463e-15
264 -1.11022302463e-15
278 -1.11022302463e-15
280 -1.11022302463e-15
281 -1.11022302463e-15
297 -1.11022302463e-15
302 -1.11022302463e-15
303 -1.11022302463e-15
313 -1.11022302463e-15
318 -1.11022302463e-15
321 -1.11022302463e-15
327 -1.11022302463e-15
328 -1.11022302463e-15
329 -1.11022302463e-15
333 -1.11022302463e-15
334 -1.11022302463e-15
336 -1.11022302463e-15
339 -1.11022302463e-15
348 -1.11022302463e-15
349 -1.11022302463e-15
354 -1.11022302463e-15
355 -1.11022302463e-15
359 -1.11022302463e-15
360 -1.11022302463e-15
361 -1.11022302463e-15
373 -1.11022302463e-15
375 -1.11022302463e-15
377 -1.11022302463e-15
378 -1.11022302463e-15
379 -1.11022302463e-15
380 -1.11022302463e-15
381 -1.11022302463e-15
383 -1.11022302463e-15
392 -1.11022302463e-15
403 -1.11022302463e-15
404 -1.11022302463e-15
405 -1.11022302463e-15
409 -1.11022302463e-15
415 -1.11022302463e-15
424 -1.11022302463e-15
427 -1.11022302463e-15
431 -1.11022302463e-15
439 -1.11022302463e-15
441 -1.11022302463e-15
442 -1.11022302463e-15
448 -1.11022302463e-15
450 -1.11022302463e-15
451 -1.11022302463e-15
454 -1.11022302463e-15
455 -1.11022302463e-15
456 -1.11022302463e-15
460 -1.11022302463e-15
461 -1.11022302463e-15
462 -1.11022302463e-15
464 -1.11022302463e-15
470 -1.11022302463e-15
472 -1.11022302463e-15
473 -1.11022302463e-15
475 -1.11022302463e-15
479 -1.11022302463e-15
481 -1.11022302463e-15
482 -1.11022302463e-15
483 -1.11022302463e-15
490 -1.11022302463e-15
491 -1.11022302463e-15
494 -1.11022302463e-15
496 -1.11022302463e-15
500 -1.11022302463e-15
502 -1.11022302463e-15
504 -1.11022302463e-15
505 -1.11022302463e-15
510 -1.11022302463e-15
511 -1.11022302463e-15
513 -1.11022302463e-15
514 -1.11022302463e-15
517 -1.11022302463e-15
523 -1.11022302463e-15
524 -1.11022302463e-15
528 -1.11022302463e-15
533 -1.11022302463e-15
535 -1.11022302463e-15
538 -1.11022302463e-15
541 -1.11022302463e-15
542 -1.11022302463e-15
546 -1.11022302463e-15
554 -1.11022302463e-15
557 -1.11022302463e-15
558 -1.11022302463e-15
560 -1.11022302463e-15
561 -1.11022302463e-15
567 -1.11022302463e-15
570 -1.11022302463e-15
573 -1.11022302463e-15
574 -1.11022302463e-15
580 -1.11022302463e-15
582 -1.11022302463e-15
586 -1.11022302463e-15
587 -1.11022302463e-15
588 -1.11022302463e-15
589 -1.11022302463e-15
593 -1.11022302463e-15
595 -1.11022302463e-15
597 -1.11022302463e-15
602 -1.11022302463e-15
603 -1.11022302463e-15
605 -1.11022302463e-15
613 -1.11022302463e-15
614 -1.11022302463e-15
622 -1.11022302463e-15
625 -1.11022302463e-15
626 -1.11022302463e-15
632 -1.11022302463e-15
633 -1.11022302463e-15
634 -1.11022302463e-15
636 -1.11022302463e-15
639 -1.11022302463e-15
641 -1.11022302463e-15
643 -1.11022302463e-15
644 -1.11022302463e-15
645 -1.11022302463e-15
646 -1.11022302463e-15
648 -1.11022302463e-15
651 -1.11022302463e-15
663 -1.11022302463e-15
665 -1.11022302463e-15
671 -1.11022302463e-15
675 -1.11022302463e-15
684 -1.11022302463e-15
695 -1.11022302463e-15
702 -1.11022302463e-15
707 -1.11022302463e-15
708 -1.11022302463e-15
}}}

頑張ってそれが何であるか数えると

| 素性番号   | 重み           | 意味                      |
| :--------: | :------------: | :-----------------------: |
| 50         | -27.8812582836 | 直後顔=yor                |
| 244        | -20.0520670117 | 'ん'                      |
| 182        | -16.886084596  | 'お'                      |
| 44         | -16.679789583  | 直前顔=yor                |
| 49         | -14.8436367105 | 直後顔=null               |
| 238        | 14.5004222017  | る                        |
| 168        | 13.3448873473  | '、'                      |
| 52         | -12.5624574293 | 直後顔=odo                |
| 63         | 10.8241266759  | 一つ次接=Cont             |
| 209        | -10.2455500226 | 'で'                      |
| 306        | 9.90425554177  | 'ー'                      |
| 681        | -9.6           | '！'                      |
| 43         | -9.35958020502 | 直前顔=null               |
| 248        | 9.19005843791  | 'イ'                      |
| 216        | -8.88314803584 | 'ピ'                      |
| 178        | -8.40672343475 | 'う'                      |
| 205        | -8.20637250669 | 'テ'                      |
| 206        | 8.1039151257   | 'デ'                      |
| 68         | 7.28590807509  | 一つ次接=Exemp            |
| 239        | 7.14534207071  | 'れ'                      |
| 235        | -6.84362839011 | 'よ'                      |

表層についてはどうでもよかったのかも

## 表層なし、イライラ除く

訓練データを 2/3
テストデータを 1/3

 > 比率を変えると随分と数字が変わる！

### balanced

Accuracy = 72.381% (76/105) (classification)

|        | Prec               | Rec                 | F1                 |
| :----- | :---               | :--                 | :-----             |
| null   | 0.6829268292682927 | 0.9032258064516129  | 0.7777777777777779 |
| yor    | 0.8260869565217391 | 0.7916666666666666  | 0.8085106382978723 |
| ai     | 0.9230769230769231 | 0.631578947368421   | 0.7499999999999999 |
| odo    | 0.5217391304347826 | 0.6                 | 0.5581395348837209 |
| ika    | 1                  | 0.16666666666666666 | 0.2857142857142857 |
| haj    | 1                  | 0.8                 | 0.8888888888888888 |

Accuracy = 66.6667% (70/105) (classification)
| null | 0.5957446808510638 | 0.9655172413793104 | 0.7368421052631579  |
| yor  | 0.9333333333333333 | 0.5384615384615384 | 0.6829268292682926  |
| ai   | 0.875              | 0.4827586206896552 | 0.6222222222222222  |
| odo  | 1                  | 0.5555555555555556 | 0.7142857142857143  |
| ika  | 0.3157894736842105 | 0.6666666666666666 | 0.42857142857142855 |
| haj  | 1                  | 1                  | 1                   |

ikaはわざわざ追加してやってこれなのだから、
これは良いのではないか

## 表層全部、イライラ除く、balanced

Accuracy = 96.1905% (101/105) (classification)

|        | Prec               | Rec                | F1                 |
| :----- | :---               | :--                | :-----             |
| null   | 0.9487179487179487 | 0.9487179487179487 | 0.9487179487179486 |
| yor    | 1                  | 0.9545454545454546 | 0.9767441860465117 |
| ai     | 0.9333333333333333 | 1                  | 0.9655172413793105 |
| odo    | 1                  | 0.9230769230769231 | 0.9600000000000002 |
| ika    | 0.9375             | 1                  | 0.9677419354838711 |
| haj    | 1                  | 1                  | 1                  |

Accuracy = 78.0952% (82/105) (classification)

|        | Prec               | Rec                | F1                 |
| :----- | :---               | :--                | :-----             |
| null | 0.6779661016949152 | 0.975609756097561  | 0.8                |
| yor  | 1                  | 0.75               | 0.8571428571428572 |
| ai   | 0.8461538461538461 | 0.55               | 0.6666666666666666 |
| odo  | 0.9230769230769231 | 0.8                | 0.8571428571428572 |
| ika  | 0.875              | 0.6363636363636364 | 0.7368421052631579 |
| haj  | nan                | nan                | nan                |

Accuracy = 71.4286% (75/105) (classification)

|        | Prec               | Rec                | F1                 |
| :----- | :---               | :--                | :-----             |
| null | 0.6170212765957447 | 0.90625            | 0.7341772151898734 |
| yor  | 0.8125             | 0.65               | 0.7222222222222222 |
| ai   | 0.7058823529411765 | 0.7058823529411765 | 0.7058823529411765 |
| odo  | 0.8666666666666667 | 0.6842105263157895 | 0.7647058823529413 |
| ika  | 0.7777777777777778 | 0.4666666666666667 | 0.5833333333333334 |
| haj  | 1                  | 0.5                | 0.6666666666666666 |

